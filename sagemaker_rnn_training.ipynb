{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SageMaker RNN Training for Brain-to-Text Model\n",
        "\n",
        "This notebook trains the RNN model for brain-to-text decoding using AWS SageMaker with data from S3 and checkpoint saving to S3.\n",
        "\n",
        "**Uses the existing training infrastructure from the `model_training` folder.**\n",
        "\n",
        "## Setup and Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install omegaconf h5py torchaudio boto3 sagemaker\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import h5py\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import logging\n",
        "import json\n",
        "import pickle\n",
        "import math\n",
        "import random\n",
        "import boto3\n",
        "import tempfile\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import sys\n",
        "from omegaconf import OmegaConf\n",
        "import sagemaker\n",
        "from sagemaker.session import Session\n",
        "\n",
        "# Add model_training directory to Python path\n",
        "sys.path.append('model_training')\n",
        "\n",
        "# Import existing training components\n",
        "from rnn_trainer import BrainToTextDecoder_Trainer\n",
        "from dataset import BrainToTextDataset, train_test_split_indicies\n",
        "from rnn_model import GRUDecoder\n",
        "\n",
        "# Set up device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## S3 Configuration and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# S3 Configuration\n",
        "S3_BUCKET_NAME = '4k-woody-btt'\n",
        "S3_DATA_PREFIX = '4k/data/hdf5_data_final/'  # Base path for training data\n",
        "S3_CHECKPOINT_PREFIX = 'checkpoints/'\n",
        "\n",
        "# Initialize S3 client\n",
        "s3_client = boto3.client('s3')\n",
        "\n",
        "# Get SageMaker session for additional utilities\n",
        "sagemaker_session = sagemaker.Session()\n",
        "\n",
        "print(f\"S3 Bucket: {S3_BUCKET_NAME}\")\n",
        "print(f\"Data prefix: {S3_DATA_PREFIX}\")\n",
        "print(f\"Checkpoint prefix: {S3_CHECKPOINT_PREFIX}\")\n",
        "print(f\"Expected data structure: s3://{S3_BUCKET_NAME}/{S3_DATA_PREFIX}{{date}}/data_train.hdf5\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## S3 Data Loading and Checkpoint Management\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# S3 Data Loading Utilities\n",
        "class S3DataLoader:\n",
        "    def __init__(self, bucket_name, data_prefix):\n",
        "        self.bucket_name = bucket_name\n",
        "        self.data_prefix = data_prefix\n",
        "        self.s3_client = boto3.client('s3')\n",
        "        \n",
        "    def list_available_dates(self):\n",
        "        \"\"\"List all available training dates in the S3 bucket\"\"\"\n",
        "        response = self.s3_client.list_objects_v2(\n",
        "            Bucket=self.bucket_name,\n",
        "            Prefix=self.data_prefix,\n",
        "            Delimiter='/'\n",
        "        )\n",
        "        \n",
        "        dates = []\n",
        "        if 'CommonPrefixes' in response:\n",
        "            for prefix in response['CommonPrefixes']:\n",
        "                # Extract date from path like \"4k/data/hdf5_data_final/t15.2023.08.11/\"\n",
        "                date_path = prefix['Prefix'].rstrip('/')\n",
        "                date = os.path.basename(date_path)\n",
        "                if date.startswith('t'):  # Filter for training dates\n",
        "                    dates.append(date)\n",
        "        \n",
        "        return sorted(dates)\n",
        "    \n",
        "    def download_file(self, s3_key, local_path):\n",
        "        \"\"\"Download a file from S3 to local storage\"\"\"\n",
        "        try:\n",
        "            self.s3_client.download_file(self.bucket_name, s3_key, local_path)\n",
        "            logger.info(f\"Downloaded {s3_key} to {local_path}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to download {s3_key}: {str(e)}\")\n",
        "            return False\n",
        "    \n",
        "    def download_data_to_local(self, local_data_dir, specific_dates=None):\n",
        "        \"\"\"Download training data from S3 to local directory structure\n",
        "        \n",
        "        Args:\n",
        "            local_data_dir: Local directory to create the data structure\n",
        "            specific_dates: List of specific dates to download (e.g., ['t15.2023.08.11'])\n",
        "                          If None, downloads all available dates\n",
        "        \"\"\"\n",
        "        if specific_dates is None:\n",
        "            # Get all available dates\n",
        "            dates = self.list_available_dates()\n",
        "        else:\n",
        "            dates = specific_dates\n",
        "            \n",
        "        # Create local data directory structure\n",
        "        os.makedirs(local_data_dir, exist_ok=True)\n",
        "        downloaded_files = []\n",
        "        \n",
        "        logger.info(f\"Found {len(dates)} training dates: {dates}\")\n",
        "        \n",
        "        for date in dates:\n",
        "            # Create date subdirectory\n",
        "            date_dir = os.path.join(local_data_dir, date)\n",
        "            os.makedirs(date_dir, exist_ok=True)\n",
        "            \n",
        "            # Construct the S3 key for this date's training data\n",
        "            s3_key = f\"{self.data_prefix}{date}/data_train.hdf5\"\n",
        "            \n",
        "            # Local file path\n",
        "            local_path = os.path.join(date_dir, \"data_train.hdf5\")\n",
        "            \n",
        "            if self.download_file(s3_key, local_path):\n",
        "                downloaded_files.append(local_path)\n",
        "            else:\n",
        "                logger.warning(f\"Failed to download data for date: {date}\")\n",
        "        \n",
        "        logger.info(f\"Downloaded {len(downloaded_files)} files to {local_data_dir}\")\n",
        "        return local_data_dir, downloaded_files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# S3 Checkpoint Manager\n",
        "class S3CheckpointManager:\n",
        "    def __init__(self, bucket_name, checkpoint_prefix):\n",
        "        self.bucket_name = bucket_name\n",
        "        self.checkpoint_prefix = checkpoint_prefix\n",
        "        self.s3_client = boto3.client('s3')\n",
        "        \n",
        "    def save_checkpoint(self, model, optimizer, epoch, loss, metrics=None, is_best=False):\n",
        "        \"\"\"Save model checkpoint to S3\"\"\"\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            'metrics': metrics or {}\n",
        "        }\n",
        "        \n",
        "        # Create temporary file\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix='.pth') as tmp_file:\n",
        "            torch.save(checkpoint, tmp_file.name)\n",
        "            \n",
        "            # Determine S3 key\n",
        "            if is_best:\n",
        "                s3_key = f\"{self.checkpoint_prefix}best_checkpoint.pth\"\n",
        "            else:\n",
        "                s3_key = f\"{self.checkpoint_prefix}checkpoint_epoch_{epoch}.pth\"\n",
        "            \n",
        "            # Upload to S3\n",
        "            try:\n",
        "                self.s3_client.upload_file(tmp_file.name, self.bucket_name, s3_key)\n",
        "                logger.info(f\"Saved checkpoint to s3://{self.bucket_name}/{s3_key}\")\n",
        "                \n",
        "                # Clean up temporary file\n",
        "                os.unlink(tmp_file.name)\n",
        "                return True\n",
        "                \n",
        "            except Exception as e:\n",
        "                logger.error(f\"Failed to upload checkpoint: {str(e)}\")\n",
        "                os.unlink(tmp_file.name)\n",
        "                return False\n",
        "    \n",
        "    def load_checkpoint(self, s3_key, model, optimizer=None):\n",
        "        \"\"\"Load model checkpoint from S3\"\"\"\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix='.pth') as tmp_file:\n",
        "            try:\n",
        "                self.s3_client.download_file(self.bucket_name, s3_key, tmp_file.name)\n",
        "                checkpoint = torch.load(tmp_file.name, map_location=device)\n",
        "                \n",
        "                model.load_state_dict(checkpoint['model_state_dict'])\n",
        "                \n",
        "                if optimizer and 'optimizer_state_dict' in checkpoint:\n",
        "                    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "                \n",
        "                logger.info(f\"Loaded checkpoint from s3://{self.bucket_name}/{s3_key}\")\n",
        "                \n",
        "                # Clean up\n",
        "                os.unlink(tmp_file.name)\n",
        "                \n",
        "                return checkpoint\n",
        "                \n",
        "            except Exception as e:\n",
        "                logger.error(f\"Failed to load checkpoint: {str(e)}\")\n",
        "                os.unlink(tmp_file.name)\n",
        "                return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enhanced Trainer with S3 Checkpoint Support\n",
        "class S3EnhancedTrainer(BrainToTextDecoder_Trainer):\n",
        "    \"\"\"Enhanced trainer that saves checkpoints to S3\"\"\"\n",
        "    \n",
        "    def __init__(self, args, s3_checkpoint_manager):\n",
        "        # Initialize the parent trainer\n",
        "        super().__init__(args)\n",
        "        self.s3_checkpoint_manager = s3_checkpoint_manager\n",
        "        \n",
        "    def save_checkpoint(self, epoch, is_best=False):\n",
        "        \"\"\"Override the checkpoint saving to use S3\"\"\"\n",
        "        if hasattr(self, 'model') and hasattr(self, 'optimizer'):\n",
        "            # Get current metrics\n",
        "            metrics = {\n",
        "                'epoch': epoch,\n",
        "                'best_val_loss': self.best_val_loss,\n",
        "                'best_val_PER': self.best_val_PER\n",
        "            }\n",
        "            \n",
        "            # Save to S3\n",
        "            success = self.s3_checkpoint_manager.save_checkpoint(\n",
        "                self.model, \n",
        "                self.optimizer, \n",
        "                epoch, \n",
        "                self.best_val_loss, \n",
        "                metrics, \n",
        "                is_best\n",
        "            )\n",
        "            \n",
        "            if success:\n",
        "                self.logger.info(f\"Checkpoint saved to S3 successfully\")\n",
        "            else:\n",
        "                self.logger.error(f\"Failed to save checkpoint to S3\")\n",
        "                \n",
        "            return success\n",
        "        else:\n",
        "            self.logger.warning(\"Model or optimizer not initialized, cannot save checkpoint\")\n",
        "            return False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Training Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the existing training configuration\n",
        "config_path = 'model_training/rnn_args.yaml'\n",
        "args = OmegaConf.load(config_path)\n",
        "\n",
        "# Modify configuration for SageMaker environment\n",
        "args.dataset.dataset_dir = '/tmp/hdf5_data_final'  # Will be set after downloading from S3\n",
        "args.output_dir = '/tmp/trained_models/baseline_rnn'\n",
        "args.checkpoint_dir = '/tmp/trained_models/baseline_rnn/checkpoint'\n",
        "\n",
        "# Create local directories\n",
        "os.makedirs(args.output_dir, exist_ok=True)\n",
        "os.makedirs(args.checkpoint_dir, exist_ok=True)\n",
        "\n",
        "print(\"Training Configuration:\")\n",
        "print(f\"Dataset directory: {args.dataset.dataset_dir}\")\n",
        "print(f\"Output directory: {args.output_dir}\")\n",
        "print(f\"Checkpoint directory: {args.checkpoint_dir}\")\n",
        "print(f\"Number of training batches: {args.num_training_batches}\")\n",
        "print(f\"Number of sessions: {len(args.dataset.sessions)}\")\n",
        "print(f\"Sessions: {args.dataset.sessions[:5]}...\")  # Show first 5 sessions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download Data from S3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize S3 data loader\n",
        "s3_data_loader = S3DataLoader(S3_BUCKET_NAME, S3_DATA_PREFIX)\n",
        "\n",
        "# List available training dates\n",
        "available_dates = s3_data_loader.list_available_dates()\n",
        "print(f\"Found {len(available_dates)} training dates in S3:\")\n",
        "for date in available_dates[:10]:  # Show first 10\n",
        "    print(f\"  - {date}\")\n",
        "if len(available_dates) > 10:\n",
        "    print(f\"  ... and {len(available_dates) - 10} more\")\n",
        "\n",
        "# Filter dates to match the sessions in the config\n",
        "config_sessions = set(args.dataset.sessions)\n",
        "available_sessions = [date for date in available_dates if date in config_sessions]\n",
        "\n",
        "print(f\"\\nMatching sessions in S3: {len(available_sessions)}\")\n",
        "print(f\"Config sessions: {len(config_sessions)}\")\n",
        "\n",
        "# Download data to local directory structure\n",
        "local_data_dir = '/tmp/hdf5_data_final'\n",
        "downloaded_dir, downloaded_files = s3_data_loader.download_data_to_local(\n",
        "    local_data_dir, \n",
        "    available_sessions\n",
        ")\n",
        "\n",
        "# Update the dataset directory in config\n",
        "args.dataset.dataset_dir = local_data_dir\n",
        "\n",
        "print(f\"\\nDownloaded {len(downloaded_files)} files to: {downloaded_dir}\")\n",
        "print(f\"Updated dataset directory: {args.dataset.dataset_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize S3 checkpoint manager\n",
        "s3_checkpoint_manager = S3CheckpointManager(S3_BUCKET_NAME, S3_CHECKPOINT_PREFIX)\n",
        "\n",
        "# Initialize the enhanced trainer with S3 checkpoint support\n",
        "trainer = S3EnhancedTrainer(args, s3_checkpoint_manager)\n",
        "\n",
        "print(\"Trainer initialized successfully!\")\n",
        "print(f\"Model device: {trainer.device}\")\n",
        "print(f\"Number of model parameters: {sum(p.numel() for p in trainer.model.parameters())}\")\n",
        "print(f\"Training batches: {args.num_training_batches}\")\n",
        "print(f\"Validation frequency: every {args.batches_per_val_step} batches\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start training\n",
        "logger.info(\"Starting training...\")\n",
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    # Run the training\n",
        "    metrics = trainer.train()\n",
        "    \n",
        "    training_time = time.time() - start_time\n",
        "    logger.info(f\"Training completed in {training_time:.2f} seconds ({training_time/3600:.2f} hours)\")\n",
        "    \n",
        "    # Save final checkpoint to S3\n",
        "    trainer.save_checkpoint(args.num_training_batches, is_best=False)\n",
        "    \n",
        "    print(\"✅ Training completed successfully!\")\n",
        "    print(f\"Final metrics: {metrics}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    logger.error(f\"Training failed: {str(e)}\")\n",
        "    raise e\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Training History and Cleanup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save training history to S3\n",
        "training_history = {\n",
        "    'training_time': training_time,\n",
        "    'final_metrics': metrics,\n",
        "    'config': OmegaConf.to_yaml(args),\n",
        "    'sessions_used': available_sessions,\n",
        "    'checkpoints_saved': True\n",
        "}\n",
        "\n",
        "with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json') as tmp_file:\n",
        "    json.dump(training_history, tmp_file, indent=2)\n",
        "    \n",
        "    try:\n",
        "        s3_client.upload_file(\n",
        "            tmp_file.name, \n",
        "            S3_BUCKET_NAME, \n",
        "            f\"{S3_CHECKPOINT_PREFIX}training_history.json\"\n",
        "        )\n",
        "        logger.info(\"Training history saved to S3\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to save training history: {str(e)}\")\n",
        "    finally:\n",
        "        os.unlink(tmp_file.name)\n",
        "\n",
        "# Clean up local data directory\n",
        "try:\n",
        "    shutil.rmtree(local_data_dir)\n",
        "    logger.info(f\"Cleaned up local data directory: {local_data_dir}\")\n",
        "except Exception as e:\n",
        "    logger.warning(f\"Failed to clean up local data directory: {str(e)}\")\n",
        "\n",
        "# Clean up local model directories\n",
        "try:\n",
        "    shutil.rmtree(args.output_dir)\n",
        "    shutil.rmtree(args.checkpoint_dir)\n",
        "    logger.info(\"Cleaned up local model directories\")\n",
        "except Exception as e:\n",
        "    logger.warning(f\"Failed to clean up local model directories: {str(e)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display training summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total training time: {training_time:.2f} seconds ({training_time/3600:.2f} hours)\")\n",
        "print(f\"Training batches completed: {args.num_training_batches}\")\n",
        "print(f\"Sessions used: {len(available_sessions)}\")\n",
        "print(f\"Best validation loss: {trainer.best_val_loss:.4f}\")\n",
        "print(f\"Best validation PER: {trainer.best_val_PER:.4f}\")\n",
        "print(f\"\\nS3 Storage:\")\n",
        "print(f\"  Data source: s3://{S3_BUCKET_NAME}/{S3_DATA_PREFIX}\")\n",
        "print(f\"  Checkpoints saved to: s3://{S3_BUCKET_NAME}/{S3_CHECKPOINT_PREFIX}\")\n",
        "print(f\"  Training history: s3://{S3_BUCKET_NAME}/{S3_CHECKPOINT_PREFIX}training_history.json\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Load and Test a Checkpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Load the best checkpoint\n",
        "try:\n",
        "    checkpoint = s3_checkpoint_manager.load_checkpoint(\n",
        "        f\"{S3_CHECKPOINT_PREFIX}best_checkpoint.pth\", \n",
        "        trainer.model, \n",
        "        trainer.optimizer\n",
        "    )\n",
        "    \n",
        "    if checkpoint:\n",
        "        print(\"Successfully loaded best checkpoint:\")\n",
        "        print(f\"  Epoch: {checkpoint['epoch']}\")\n",
        "        print(f\"  Loss: {checkpoint['loss']:.4f}\")\n",
        "        print(f\"  Metrics: {checkpoint['metrics']}\")\n",
        "    else:\n",
        "        print(\"Failed to load checkpoint\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"Error loading checkpoint: {str(e)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Final Model and Training History\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save final model\n",
        "final_metrics = {\n",
        "    'train_loss': training_history['train_loss'][-1],\n",
        "    'val_loss': training_history['val_loss'][-1],\n",
        "    'epoch': config['training']['num_epochs'],\n",
        "    'best_val_loss': best_val_loss,\n",
        "    'total_training_time': total_time\n",
        "}\n",
        "\n",
        "success = checkpoint_manager.save_checkpoint(\n",
        "    model, optimizer, config['training']['num_epochs'], \n",
        "    training_history['val_loss'][-1], final_metrics, False\n",
        ")\n",
        "\n",
        "if success:\n",
        "    logger.info(\"Final model saved successfully\")\n",
        "else:\n",
        "    logger.error(\"Failed to save final model\")\n",
        "\n",
        "# Save training history to S3\n",
        "with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json') as tmp_file:\n",
        "    json.dump(training_history, tmp_file, indent=2)\n",
        "    \n",
        "    try:\n",
        "        s3_client.upload_file(\n",
        "            tmp_file.name, \n",
        "            S3_BUCKET_NAME, \n",
        "            f\"{S3_CHECKPOINT_PREFIX}training_history.json\"\n",
        "        )\n",
        "        logger.info(\"Training history saved to S3\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to save training history: {str(e)}\")\n",
        "    finally:\n",
        "        os.unlink(tmp_file.name)\n",
        "\n",
        "# Clean up temporary data directory\n",
        "import shutil\n",
        "shutil.rmtree(temp_data_dir)\n",
        "logger.info(f\"Cleaned up temporary directory: {temp_data_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
